---
title: "Worflow development"
subtitle: "Buffalo Pound Water Treatment Plant (BPWTP) routine laboratory data synthesis"
author:
  - Megan L. Larsen^[Wilfrid Laurier University, mlarsen@wlu.ca]
  - Anthony A.P. Baron^[University of Saskatchewan, anthony.baron@usask.ca]
  - Blair Kardash^[Buffalo Pound Water Treatment Plant]
  - Helen M. Baulch^[University of Saskatchewan, helen.baulch@usask.ca]
  - Jason J. Venkiteswaran^[Wilfrid Laurier University, jvenkiteswaran@wlu.ca]
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = F)

# load libraries
library(bpwtpR)
library(pander)
library(tidyverse)
```
# Project Summary

BPWTP routine lab data from 1980 - 2013 were converted from Lotus 123 to xls by B. Kardash. Though data from earlier exists, there was a lack of consistency in the data collection measures, so those data were excluded from the data base. `build_database` scrapes information from .xls files and compiles all the information into a single data sheet. The full historical dataset includes all measured variables from 1980 to 2019. Data that are actively being created during the year are designated by an `active` tag in the file name.

The scraped information is then processed through a variety of steps to update parameter to a consistent naming convention and calculate a variety of additional metrics.

The final data set includes all measured and calculated water quality metrics assigned by the sampling location in the water treatment process.  

## Objectives  
1. Synthesize data into a single data file

# Introduction

Buffalo Pound Water Treatment Plant (BPWTP) ... pull text from mitacs proposal

## Source waters, muncipal supply, and watershed contributions

## Water treatment processes and sampling
Include information about the water treatment process, include graphic and description of sites.

There are six measurement stations:
1. Raw: located at the plant intake on Buffalo Pound Lake near the dam on the southeastern corner. Samples from this location are run for the complete suite of physical, major/minor, biological, and bacteriological water quality parameters. 
2. PreFM: collect before the Flash Mix (FM) is added.
3. Channel:
4. MMFA/MMFL: Mixed Media Filter
5. PreGAC: Granualized Activated Carbon
6. Clearwell: Pre-distribution water 

## Laboratory methods + accredidation
Details about the lab...


# 40 year data synthesis

## Data availablity and structure

BPWTP routine laboratory data has been collected stored as Lotus 123 (`.123`) or Microsoft Excel (`.xls`) since the late 1970s. Data from 1980 - 2013 were converted from Lotus 123 to xls by B. Kardash. Though earlier data exists, a lack of consistency in the data collection protocols have excluded these data base for inclusion. 

## Scraping data from .xls file
## Data processing

```{r build_scrapeddata}

# build the database with 1980 - 2019 data
build_database(datadir = "./data/labdat_datafiles/", 
               outdir = "./data", 
               outfile = "BPWTP_routinelabdata_historicalbase_scraped.csv")
```

```{r load_scrapedlabdat}

# read in the scraped labdat dataset
labdat <- read_labdat(datadir = "./data/", 
                      labdat_file = "BPWTP_routinelabdata_historicalbase_scraped.csv") %>%
  mutate(result = as.character(result), 
         parameter = as.character(parameter), 
         unit = as.character(unit),
         year = year(datetime_ymd.hms),
         month = month(datetime_ymd.hms, label = T, abbr = T)) 
```

```{r}
# >> ML: Need to scrape DOC profile information from all xls files and append to database
```

The original BPWTP routine lab data template structure in lotus.123 or .xls set dates based on the first day in the week. Due to annual variation and the template structure, some years have more date columns than others leading to date duplication in the dataset.

```{r remove_duplicatedates}

labdat_updatedates <- labdat[-which(labdat$year != labdat$sheet_year),]

```
Parameter names have been updated and/or changed throughout the last 40 years. To account for these parameter changes, we update all parameters in the datasheet to a consistent naming convention.

```{r update_labdatparameters}

labdat_updatedparms <- update_parameters(labdat_updatedates, data_validation = TRUE)

# NOTE: various parameter naming issues have been addressed in
#   the parameters.csv file that contains an updated parameter and unit if
#   necessary. Running the `update_parameters` function with the data_validation
#   function allows the user to see the original parameter and the updated
#   parameter.
# NOTE: there should be 0 rows returned in console
```

### Removing specific data types

Some of the scraped parameters have dates or categories as result values.

These data, including the on/off dates for the granualize activated carbon filters (GAC), ice
 dates, and PAC dates are removed from the dataset and stored as a separate corrected file. 
There should be 6 values per year (max *n* = 234), however, some do not have dates recorded in the data files.

```{r operationaldates}
operation_dates = c("GACs ON", "GACs OFF", "Ice OFF", "Ice ON", "PAC OFF", "PAC ON")

labdat_updatedparms_opdates <- labdat_updatedparms %>% 
  filter(parameter_updated %in% operation_dates) %>%
  mutate(year = year(datetime_ymd.hms)) %>%
  filter(!is.na(result))
  
# >> ML: Obtain operational dates from elsewhere. Some data from Emily
```
The plant utilizes two intake points from Buffalo Pound Lake denoted as East or West. As with the date information, these data will be stored and corrected separately.

```{r operationalintakes}

labdat_updatedparms_intake <- labdat_updatedparms %>% filter(parameter_updated == "Intake")

```

```{r remove_operationaldata}
labdat_updatedparms <- labdat_updatedparms %>% 
  filter(!parameter_updated %in% operation_dates, parameter_updated != "Intake")
```

### Data corrections

Scraping data from xls files requires checking that the data are both copied in correctly, but also that they contain no special characters that may interfere with calculations. 

There are several data cases that need to be examined including:
 1. "--" = calculated value where measured values are bdl
 2. "<" & "<*" = values that are below detection limit (bdl) should be replaced with 0 (as per BK).
 3. Values above the detection limit (">", or TNTC) will be excluded from the data set

In addition, we also remove values that were calculated within the spread so that they can be updated reproducibly with coded functions.

```{r extractspecialcases}
# calculated values
labdat_calcvals <- filter(labdat_updatedparms, parm_eval == "calculated_insheet")

# results with special characters
labdat_bdl <- filter(labdat_updatedparms, grepl(pattern = "[<]", x = result))
labdat_adl <- filter(labdat_updatedparms, result == "TNTC" | grepl(pattern = "[>]", x = result))
labdat_mod <- filter(labdat_updatedparms, grepl(pattern = "[*]", x = result))

```

Data that are being corrected by one method or another are denoted by a result flag (result_flag) with the following annotations:
- bdl: below detection limit (<, <**)
- adl: above detection limit (>, TNTC)
- corrected: biological data with x10-3 multiplied by 1000

Both the corrected (result) and original data (result_org) are saved in the data file. 

```{r updateresults}
# >> ML: need to write replacement functions for bdl, adl, mod
# remove calculated values
labdat_updatedresults <- labdat_updatedparms %>%
                              filter(parm_eval != "calculated_insheet") %>%
							  mutate(result = update_results(result),
							  mutate(result = gsub(pattern = "unavailable", 
													replacement = NA, x = result))

```

```{r}
# once the above subsetted data is confirmed, it can be added back to the full dataset
labdat_trimmed <- labdat_updatedresults %>%
  select(-c(parameter, unit)) %>%
  rename(parameter = "parameter_updated",
         unit = "unit_updated") %>%
  mutate(result = as.numeric(result))

# apply data corrections
labdat_corrected <- convert_biocounts(labdat = labdat_trimmed)


# Values that are calculated (parm_eval == "calculated") are recalculated with `apply_calculations`
# apply the calculation functions
labdat_cals <- apply_calculations(labdat = labdat_corrected)


# append the newly calculated values to the labdat file
labdat_updated <- append_calc_values(labdat = labdat_corrected, 
                                            labdat_calcs = labdat_cals)

# prepare the final datafile 
labdat_updated <- labdat_updated %>%
  mutate(year = year(datetime_ymd.hms),
         month = month(datetime_ymd.hms, label = T, abbr = T),
         week = week(datetime_ymd.hms)) %>%
  select(datasheet:datetime_ymd.hms, year, 
         month, week, parameter:result)

```

The complete dataset (1980 - 2019) will not be modified following this process.
 
```{r write_updatedfiles}

write_datafile(file = labdat_updated, 
               outdir = "./data",
               outfilename = "BPWTP_routinelabdata_complete.csv")

```

## Incorporating new data
New data are recorded on a weekly basis into the active tagged datasheet. These new data are incorporated into the database using the complete dataset as its functional base. To preserve data integrity, newly added information will be saved as a separate data file. `update_database` scrapes data from the active spreadsheet, passes it through a parameter and conversion sequence and then finally appends the data into the datasheet. 

## Data Validation
Ensuring that all information is translated appropriately is of great importance for maintaining compliance. We have used in-sheet calculated values to compare to our in-script caluclated values and used spot checking methods to make sure that the data align with the original files. Summary files for each month have also been spot checked against the historical datasets. 

# Reporting
## Historical calculations
## Report types


# Summary

`build_database` scrapes information from .xls files and compiles all the information into a single data sheet. The full historical dataset includes all measured variables from 1980 to 2019. Data that are actively being created during the year are designated by an `active` tag in the file name. 

The scraped information is then processed through a variety of steps to update parameter to a consistent naming convention and calculate a variety of additional metrics.

The final data set includes all measured and calculated water quality metrics assigned by the sampling location in the water treatment process. 

## Acknowledgements

This project was funded by MITACS Accelerate in collaboration with Buffalo Pound Water Treatment Plant, Wilfrid Laurier University, and the University of Saskatchwan.
